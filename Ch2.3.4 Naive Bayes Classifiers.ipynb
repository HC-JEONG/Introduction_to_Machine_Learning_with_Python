{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch2.3.4 Naive Bayes Classifiers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HC-JEONG/Introduction_to_Machine_Learning_with_Python/blob/master/Ch2.3.4%20Naive%20Bayes%20Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFr9G7tqrCEs",
        "colab_type": "text"
      },
      "source": [
        "## 2.3.4 나이브 베이즈 분류기\n",
        "\n",
        "> 나이브 베이즈(naive bayes)는 선형 분류기보다 훈련 속도가 빠른 편이지만, 일반화 성능이 조금 떨어진다.\n",
        "\n",
        "> 각 특성을 개별로 취급해(독립) 파라미터를 학습하고 각 특성에서 클래스별 통계를 단순하게 취합하기 때문에 효과적이다.\n",
        "\n",
        "*   GaussianNB는 연속적인 데이터에 적용 가능하다.\n",
        "*   BernoulliNB는 이진 데이터에 적용 가능하다. 클래스별로 각 특성의 표준편차와 평균을 저장한다.\n",
        "*   MultinomialNB는 카운트 데이터에 적용 가능하다. 클래스별로 특성의 평균을 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1loaZVVe24Oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=np.array([[0,1,0,1],\n",
        "            [1,0,1,1],\n",
        "            [0,0,0,1],\n",
        "            [1,0,1,0]])\n",
        "y=np.array([0,1,0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSxAJ-yJ24Oe",
        "colab_type": "code",
        "outputId": "62c18a6b-19fd-4134-c314-895360f6b4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "counts={}\n",
        "for label in np.unique(y):\n",
        "    # 각 클래스에 대해 반복\n",
        "    # 특성마다 1이 나타난 횟수를 센다.\n",
        "    counts[label]=X[y==label].sum(axis=0)\n",
        "print(\"특성 카운트:\\n\", counts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "특성 카운트:\n",
            " {0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TTOSZlasYC_",
        "colab_type": "text"
      },
      "source": [
        "### 장단점과 매개변수\n",
        "\n",
        "> MultinomialNB와 BernoulliNB는 alpha 매개변수를 가지고 있다. alpha가 주어지면 알고리즘이 모든 특성에 양의 값을 가진 가상의 데이터 포인트를 alpha 개수만큼 추가한다. 따라서 alpha가 크면 더 완만해지고 모델의 복잡도는 낮아지지만 alpha 값이 성능 향상에 크게 기여하지는 않는다.\n",
        "\n",
        "> GaussianNB는 고차원 데이터셋에 적용하며, 다른 두 나이브 베이즈 모델은 텍스트 같은 희소한 데이터를 카운트하는 데 사용한다."
      ]
    }
  ]
}